{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the text from the pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the text from the pdf, we can use any implementation of the `PdfExtractorInterface` class. and pass the pdf data as bytes to the `extract` method.\n",
    "\n",
    "```python\n",
    "class PdfExtractorImplementation(PdfExtractorInterface):\n",
    "    def forward(self, input: bytes) -> str:\n",
    "        return \"Hello, world!\"\n",
    "\n",
    "pdf_extractor = PdfExtractorImplementation()\n",
    "text = pdf_extractor.forward(pdf_data)\n",
    "```\n",
    "\n",
    "These implementations are available in the `llm_synthesis.transformers.pdf_extraction` module.\n",
    "- `DoclingPDFExtractor`\n",
    "- `MistralPDFExtractor`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## DoclingPDFExtractor\n",
    "\n",
    "Extract Data locally with Docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_synthesis.transformers.pdf_extraction import DoclingPDFExtractor\n",
    "\n",
    "with open(\"../data/pdf_papers/test.pdf\", \"rb\") as f:\n",
    "    pdf_data = f.read()\n",
    "\n",
    "pdf_extractor = DoclingPDFExtractor(\n",
    "    pipeline=\"standard\",\n",
    "    table_mode=\"accurate\",\n",
    "    add_page_images=False,\n",
    "    use_gpu=True,\n",
    "    scale=2.0,\n",
    "    format=\"markdown\",\n",
    ")\n",
    "docling_extracted_text = pdf_extractor.forward(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(docling_extracted_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MistralPDFExtractor\n",
    "\n",
    "Extract Data with Mistral.\n",
    "\n",
    "NB: You need to have a mistral account and a valid API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "\n",
    "from llm_synthesis.transformers.pdf_extraction import MistralPDFExtractor\n",
    "\n",
    "with open(\"../data/pdf_papers/test.pdf\", \"rb\") as f:\n",
    "    pdf_data = f.read()\n",
    "\n",
    "pdf_extractor = MistralPDFExtractor(\n",
    "    structured=False\n",
    ")  # You can set the api key as an argument or in the environment variable MISTRAL_API_KEY (use a .env file)\n",
    "mistral_extracted_text = pdf_extractor.forward(pdf_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(mistral_extracted_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save that for later\n",
    "\n",
    "with open(\"../data/txt_papers/mistral/test.md\", \"w+\") as f:\n",
    "    f.write(mistral_extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make it a paper object\n",
    "with open(\"../data/txt_papers/mistral/test.md\") as f:\n",
    "    mistral_extracted_text = f.read()\n",
    "from llm_synthesis.models.paper import Paper\n",
    "\n",
    "paper = Paper(\n",
    "    id=\"test\", name=\"test\", publication_text=mistral_extracted_text, si_text=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract text from a markdown text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are available in the `llm_synthesis.transformers.text_extraction` module. From which you can extract any arbitrary text from the publication text.\n",
    "\n",
    "We currently use dspy to extract text from a markdown text.\n",
    "\n",
    "Here are a few examples of how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_synthesis.transformers.material_extraction import (\n",
    "    DspyTextExtractor,\n",
    "    make_dspy_text_extractor_signature,\n",
    ")\n",
    "from llm_synthesis.utils.dspy_utils import get_llm_from_name\n",
    "from llm_synthesis.utils.markdown_utils import remove_figs\n",
    "\n",
    "# Let's make a signature for the text extraction\n",
    "signature = make_dspy_text_extractor_signature(\n",
    "    signature_name=\"ExtractSynthesisParagraph\",\n",
    "    instructions=\"Extract the synthesis paragraph from the markdown publication text.\",\n",
    "    input_description=\"The markdown publication text to extract the synthesis paragraph from.\",\n",
    "    output_name=\"synthesis_paragraph\",\n",
    "    output_description=\"The extracted synthesis paragraph.\",\n",
    ")\n",
    "\n",
    "# Let's first remove the figures from the publication text\n",
    "paper.publication_text = remove_figs(paper.publication_text)\n",
    "\n",
    "# Let's make a language model\n",
    "lm = get_llm_from_name(\"gpt-4o-mini\", {\"temperature\": 0.0})\n",
    "\n",
    "# Let's make a text extractor\n",
    "text_extractor = DspyTextExtractor(signature, lm)\n",
    "\n",
    "# Let's extract the text\n",
    "synthesis_paragraph = text_extractor.forward(paper.publication_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesis_paragraph\n",
    "\n",
    "# Let's save that for later\n",
    "with open(\"../data/txt_papers/mistral/test_extracted_text.md\", \"w+\") as f:\n",
    "    f.write(synthesis_paragraph)\n",
    "# Let's make a signature for the structured data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the signature is to provide the llm context on what is its actual task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = make_dspy_text_extractor_signature(\n",
    "    signature_name=\"ExtractFirstParagraph\",\n",
    "    instructions=\"Extract the first paragraph from the markdown publication text.\",\n",
    "    input_description=\"The markdown publication text to extract the first paragraph from.\",\n",
    "    output_name=\"first_paragraph\",\n",
    "    output_description=\"The extracted first paragraph.\",\n",
    ")\n",
    "\n",
    "text_extractor = DspyTextExtractor(signature, lm)\n",
    "\n",
    "text_extractor.forward(paper.publication_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Structured Data from the synthesis paragraph\n",
    "\n",
    "These functions are available in the `llm_synthesis.transformers.structured_data_extraction` module. From which you can extract any arbitrary structured data from the publication text.\n",
    "\n",
    "We currently use dspy to extract structured data from a markdown text.\n",
    "\n",
    "Here are a few examples of how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_synthesis.transformers.synthesis_extraction import (\n",
    "    DspySynthesisExtractor,\n",
    "    make_dspy_synthesis_extractor_signature,\n",
    ")\n",
    "from llm_synthesis.utils.dspy_utils import get_llm_from_name\n",
    "\n",
    "# Let's make a signature for the structured data extraction\n",
    "signature = make_dspy_synthesis_extractor_signature(\n",
    "    signature_name=\"ExtractStructuredSynthesis\",\n",
    "    instructions=\"Extract the structured synthesis from the synthesis paragraph.\",\n",
    "    input_description=\"The synthesis paragraph to extract the structured synthesis from.\",\n",
    "    output_name=\"structured_synthesis\",\n",
    "    output_description=\"The extracted structured synthesis.\",\n",
    ")\n",
    "\n",
    "lm = get_llm_from_name(\"gemini-2.0-flash\", {\"temperature\": 0.0})\n",
    "# Let's make a structured data extractor\n",
    "structured_data_extractor = DspySynthesisExtractor(signature, lm)\n",
    "\n",
    "# Load synthesis paragraph\n",
    "with open(\"../data/txt_papers/mistral/test_extracted_text.md\") as f:\n",
    "    synthesis_paragraph = f.read()\n",
    "\n",
    "# Let's extract the structured data\n",
    "structured_data = structured_data_extractor.forward(synthesis_paragraph)\n",
    "\n",
    "structured_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_synthesis.utils.markdown_utils import remove_figs\n",
    "\n",
    "with open(\"../data/txt_papers/mistral/test.md\") as f:\n",
    "    publication_text = f.read()\n",
    "\n",
    "publication_text = remove_figs(publication_text)\n",
    "\n",
    "# Let's extract the structured data\n",
    "structured_data_from_publication_text = structured_data_extractor.forward(\n",
    "    publication_text\n",
    ")\n",
    "\n",
    "structured_data_from_publication_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract figures from the publication text\n",
    "\n",
    "These functions are available in the `llm_synthesis.transformers.figure_extraction` module. From which you can extract any arbitrary figures from the publication text.\n",
    "\n",
    "We currently expect the pdf_parser to embed figures in the markdown text to be able to extract figures from a markdown text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_synthesis.transformers.figure_extraction import (\n",
    "    FigureExtractorMarkdown,\n",
    ")\n",
    "\n",
    "figure_extractor = FigureExtractorMarkdown()\n",
    "\n",
    "with open(\"../data/txt_papers/mistral/test.md\") as f:\n",
    "    publication_text = f.read()\n",
    "\n",
    "figures = figure_extractor.forward(publication_text)\n",
    "\n",
    "print(f\"{len(figures)} figures was found in this paper.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Loop through each figure in the 'figures' list\n",
    "for index, figure in enumerate(figures):\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Determine if the figure is quantitative\n",
    "    is_quantitative = (\n",
    "        \"Quantitative\" if figure.quantitative else \"Not Quantitative\"\n",
    "    )\n",
    "\n",
    "    # Print figure information\n",
    "    print(\n",
    "        f\"Figure {index + 1}: {is_quantitative} - Figure Class: {figure.figure_class}\"\n",
    "    )\n",
    "\n",
    "    # Decode Base64 image data and open it using PIL\n",
    "    image_data = base64.b64decode(figure.base64_data)\n",
    "    image_stream = io.BytesIO(image_data)\n",
    "    image = Image.open(image_stream)\n",
    "\n",
    "    # Convert image to NumPy array for visualization\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    # Plot the image using Matplotlib\n",
    "    plt.imshow(image_array)\n",
    "    plt.axis(\"off\")  # Hide axes for better visual appearance\n",
    "    plt.title(f\"{is_quantitative}: {figure.figure_class}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the first figure\n",
    "\n",
    "import base64\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "# Convert base64 string to image and display\n",
    "Image(base64.b64decode(figures[0].base64_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"alt_text: \", figures[0].alt_text)\n",
    "print(\"context_before: \", figures[0].context_before)\n",
    "print(\"context_after: \", figures[0].context_after)\n",
    "print(\"figure_reference: \", figures[0].figure_reference)\n",
    "print(\"position: \", figures[0].position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract figure descriptions from the publication text\n",
    "\n",
    "These functions are available in the `llm_synthesis.transformers.figure_description` module. From which you can get figure descriptions from the publication text and figure info.\n",
    "\n",
    "The current implementation uses dspy to get figure descriptions from the publication text and figure info.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_synthesis.models.figure import FigureInfoWithPaper\n",
    "from llm_synthesis.transformers.figure_description import (\n",
    "    DspyFigureDescriptionExtractor,\n",
    "    make_dspy_figure_description_extractor_signature,\n",
    ")\n",
    "from llm_synthesis.utils.dspy_utils import get_llm_from_name\n",
    "from llm_synthesis.utils.markdown_utils import remove_figs\n",
    "\n",
    "# Let's make a signature for the figure description extraction\n",
    "signature = make_dspy_figure_description_extractor_signature(\n",
    "    signature_name=\"DspyFigureDescriptionExtractorSignature\",\n",
    "    instructions=\"Extract the figure description from the figure.\",\n",
    "    publication_text_description=\"The publication text to extract the figure description from.\",\n",
    "    si_text_description=\"The supporting information text to extract the figure description from.\",\n",
    "    figure_base64_description=\"The base64 encoded image of the figure to extract the description from.\",\n",
    "    caption_context_description=\"The text context surrounding the figure position including the figure caption and nearby paragraphs that reference this figure.\",\n",
    "    figure_position_info_description=\"The information about the figure's position in the document (e.g., 'Figure 2', 'Fig. 3a', 'Scheme 1') to help with contextual understanding.\",\n",
    "    figure_description_description=\"The extracted figure description.\",\n",
    ")\n",
    "\n",
    "lm = get_llm_from_name(\"gpt-4o-mini\", {\"temperature\": 0.0})\n",
    "\n",
    "with open(\"../data/txt_papers/mistral/test.md\") as f:\n",
    "    publication_text = f.read()\n",
    "\n",
    "publication_text = remove_figs(publication_text)\n",
    "\n",
    "figure_info_with_paper = FigureInfoWithPaper(\n",
    "    **figures[2].__dict__,\n",
    "    paper_text=publication_text,\n",
    "    si_text=\"\",\n",
    ")\n",
    "\n",
    "figure_description_extractor = DspyFigureDescriptionExtractor(signature, lm)\n",
    "\n",
    "figure_description = figure_description_extractor.forward(\n",
    "    figure_info_with_paper\n",
    ")\n",
    "\n",
    "figure_description"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
