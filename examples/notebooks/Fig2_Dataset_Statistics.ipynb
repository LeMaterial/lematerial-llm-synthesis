{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Script to plot relevant plots for Fig. 2 (NeurIPS AI4Mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from llm_synthesis.utils.style_utils import get_cmap, get_palette, set_style\n",
    "\n",
    "cmap = get_cmap()\n",
    "palette = get_palette()\n",
    "set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"LeMaterial/LeMat-Synth\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds[\"sample_for_evaluation\"].to_pandas()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"paper_published_date\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first 4 numbers of the paper_published_date\n",
    "df[\"paper_published_date\"] = df[\"paper_published_date\"].str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"source\"] is arxiv when paper_url contains arxiv.org, chemrxiv when paper_url contains chemrxiv.org, else it is \"omg24\"\n",
    "\n",
    "df[\"source\"] = df[\"paper_url\"].apply(\n",
    "    lambda x: \"arxiv\"\n",
    "    if \"arxiv.org\" in x\n",
    "    else \"chemrxiv\"\n",
    "    if \"chemrxiv.org\" in x\n",
    "    else \"omg24\"\n",
    ")\n",
    "\n",
    "df.groupby(\"source\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"material_category\", \"synthesis_method\", \"paper_published_date\", \"source\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.getcwd()\n",
    "\n",
    "# Define the full path for the output file\n",
    "file_path = os.path.join(output_dir, \"dataset_statistics_with_source.csv\")\n",
    "\n",
    "\n",
    "df[\n",
    "    [\"material_category\", \"synthesis_method\", \"paper_published_date\", \"source\"]\n",
    "].to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-generate colors for material categories\n",
    "unique_materials = sorted(df[\"material_category\"].unique())\n",
    "unique_synthesis = sorted(df[\"synthesis_method\"].unique())\n",
    "material_colors = dict(zip(unique_materials, palette))\n",
    "unique_synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all entries where synthesis_method is iCVD to CVD\n",
    "df.loc[df[\"synthesis_method\"] == \"iCVD\", \"synthesis_method\"] = \"CVD\"\n",
    "df.loc[df[\"synthesis_method\"] == \"MOCVD\", \"synthesis_method\"] = \"CVD\"\n",
    "df.loc[\n",
    "    df[\"synthesis_method\"] == \"pulsed laser deposition\", \"synthesis_method\"\n",
    "] = \"PLD\"\n",
    "df.loc[\n",
    "    df[\"synthesis_method\"] == \"molecular beam epitaxy\", \"synthesis_method\"\n",
    "] = \"MBE\"\n",
    "df.loc[\n",
    "    df[\"synthesis_method\"] == \"filtered vacuum arc deposition (FVAD)\",\n",
    "    \"synthesis_method\",\n",
    "] = \"FVAD\"\n",
    "df.loc[\n",
    "    df[\"synthesis_method\"] == \"filtered vacuum arc deposition\",\n",
    "    \"synthesis_method\",\n",
    "] = \"FVAD\"\n",
    "df.loc[\n",
    "    df[\"synthesis_method\"] == \"atomic layer deposition\",\n",
    "    \"synthesis_method\",\n",
    "] = \"ALD\"\n",
    "unique_synthesis = sorted(df[\"synthesis_method\"].unique())\n",
    "unique_synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "set_style()\n",
    "# Find top 5 most common material categories for bar plots\n",
    "material_counts = df[\"material_category\"].value_counts()\n",
    "top_5_materials = material_counts.head(7).index.tolist()\n",
    "\n",
    "print(\"ðŸ“Š MATERIAL CATEGORY ANALYSIS:\")\n",
    "print(f\"   Total categories: {len(material_counts)}\")\n",
    "print(f\"   Category counts: {dict(material_counts)}\")\n",
    "print(f\"   Top 5 for bar plots: {top_5_materials}\")\n",
    "\n",
    "\n",
    "# Create a mapping function for bar plots (group less common as \"other\")\n",
    "def group_materials_for_bars(category):\n",
    "    if category in top_5_materials:\n",
    "        return category\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "\n",
    "# Apply grouping for bar plots\n",
    "df[\"material_category_grouped\"] = df[\"material_category\"].apply(\n",
    "    group_materials_for_bars\n",
    ")\n",
    "\n",
    "# Auto-generate colors for all original categories (for heatmaps)\n",
    "unique_materials = sorted(df[\"material_category\"].unique())\n",
    "unique_synthesis = sorted(df[\"synthesis_method\"].unique())\n",
    "material_colors = dict(\n",
    "    zip(unique_materials, sns.color_palette(\"Set2\", len(unique_materials)))\n",
    ")\n",
    "\n",
    "# Auto-generate colors for grouped categories (for bar plots)\n",
    "unique_materials_grouped = sorted(df[\"material_category_grouped\"].unique())\n",
    "material_colors_grouped = dict(\n",
    "    zip(\n",
    "        unique_materials_grouped,\n",
    "        sns.color_palette(\"Set2\", len(unique_materials_grouped)),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "sources = [\"arxiv\", \"chemrxiv\", \"omg24\"]\n",
    "source_titles = [\"ArXiv\", \"ChemRxiv\", \"OMG24\"]\n",
    "\n",
    "for source, title in zip(sources, source_titles):\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"VISUALIZING: {title.upper()}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Filter data for this source\n",
    "    source_data = df[df[\"source\"] == source]\n",
    "\n",
    "    if len(source_data) == 0:\n",
    "        print(f\"No data for {source}\")\n",
    "        continue\n",
    "\n",
    "    years = sorted(source_data[\"paper_published_date\"].unique())\n",
    "\n",
    "    # =======================================================================\n",
    "    # 1. BAR PLOT: Count vs Year, colored by Material Category (Top 5 only)\n",
    "    # =======================================================================\n",
    "    print(\n",
    "        f\"\\nðŸ“Š BAR PLOT: {title} Papers Over Time by Material Category (Top 5)\"\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Prepare data for stacked bars using GROUPED categories\n",
    "    bar_data = (\n",
    "        source_data.groupby(\n",
    "            [\"paper_published_date\", \"material_category_grouped\"]\n",
    "        )\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "    )\n",
    "\n",
    "    # Create stacked bar plot\n",
    "    bar_data.plot(\n",
    "        kind=\"bar\",\n",
    "        stacked=True,\n",
    "        ax=ax,\n",
    "        color=[material_colors_grouped[col] for col in bar_data.columns],\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.8,\n",
    "    )\n",
    "\n",
    "    # Customize bar plot\n",
    "    ax.set_title(\n",
    "        f\"{title}: Research Papers by Material Category Over Time\\n(Top 5 Most Common Categories)\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=20,\n",
    "    )\n",
    "    ax.set_xlabel(\"Year\", fontsize=12)\n",
    "    ax.set_ylabel(\"Number of Papers\", fontsize=12)\n",
    "    ax.tick_params(axis=\"x\", rotation=0)\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "    ax.legend(\n",
    "        title=\"Material Category\", bbox_to_anchor=(1.05, 1), loc=\"upper left\"\n",
    "    )\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(\n",
    "            container,\n",
    "            label_type=\"center\",\n",
    "            fontweight=\"bold\",\n",
    "            labels=[str(int(v)) if v > 0 else \"\" for v in container.datavalues],\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # =======================================================================\n",
    "    # 2. HEATMAPS: Material Category vs Synthesis Method for Each Year\n",
    "    # =======================================================================\n",
    "    print(f\"\\nðŸ”¥ HEATMAPS: {title} Material vs Synthesis Method by Year\")\n",
    "\n",
    "    # Get ALL unique categories and methods across the entire dataset for consistent dimensions\n",
    "    all_materials = sorted(df[\"material_category\"].unique())\n",
    "    all_synthesis = sorted(df[\"synthesis_method\"].unique())\n",
    "\n",
    "    for year in years:\n",
    "        year_data = source_data[source_data[\"paper_published_date\"] == year]\n",
    "\n",
    "        if len(year_data) == 0:\n",
    "            continue\n",
    "\n",
    "        # Create pivot table for heatmap\n",
    "        heatmap_data = (\n",
    "            year_data.groupby([\"material_category\", \"synthesis_method\"])\n",
    "            .size()\n",
    "            .unstack(fill_value=0)\n",
    "        )\n",
    "\n",
    "        # Ensure consistent dimensions by reindexing to include ALL categories and methods\n",
    "        heatmap_data = heatmap_data.reindex(\n",
    "            index=all_materials, columns=all_synthesis, fill_value=0\n",
    "        )\n",
    "\n",
    "        # Always create heatmap (even if mostly zeros) for consistent comparison\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "        # Create heatmap with consistent color scale\n",
    "        sns.heatmap(\n",
    "            heatmap_data,\n",
    "            # annot=True,  # Show numbers\n",
    "            fmt=\"d\",  # Integer format\n",
    "            cmap=\"Blues\",  # Nice color scheme\n",
    "            ax=ax,\n",
    "            cbar_kws={\"label\": \"Number of Papers\"},\n",
    "            linewidths=0.5,  # Add grid lines\n",
    "            square=False,  # Don't force square cells\n",
    "            vmin=0,  # Consistent color scale starting at 0\n",
    "            vmax=max(3, heatmap_data.values.max()),\n",
    "        )  # Consistent max scale\n",
    "\n",
    "        ax.set_title(\n",
    "            f\"{title} {year}: Material Category vs Synthesis Method\\n({len(year_data)} papers total)\",\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "        ax.set_xlabel(\"Synthesis Method\", fontsize=12)\n",
    "        ax.set_ylabel(\"Material Category\", fontsize=12)\n",
    "\n",
    "        # Rotate x-axis labels for better readability\n",
    "        plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "        plt.setp(ax.get_yticklabels(), rotation=0)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Print summary for this year\n",
    "        total_papers = len(year_data)\n",
    "        print(f\"  ðŸ“‹ {year}: {total_papers} papers total\")\n",
    "\n",
    "        # Show breakdown\n",
    "        material_breakdown = year_data[\"material_category\"].value_counts()\n",
    "        synthesis_breakdown = year_data[\"synthesis_method\"].value_counts()\n",
    "\n",
    "        print(f\"     Materials: {dict(material_breakdown)}\")\n",
    "        print(f\"     Synthesis: {dict(synthesis_breakdown)}\")\n",
    "\n",
    "    # =======================================================================\n",
    "    # 3. SUMMARY STATS\n",
    "    # =======================================================================\n",
    "    print(f\"\\nðŸ“ˆ SUMMARY: {title}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total papers: {len(source_data)}\")\n",
    "    print(f\"Years covered: {min(years)} - {max(years)}\")\n",
    "    print(\n",
    "        f\"Material categories (original): {len(source_data['material_category'].unique())}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Material categories (bar plot): {len(source_data['material_category_grouped'].unique())}\"\n",
    "    )\n",
    "    print(f\"Synthesis methods: {len(source_data['synthesis_method'].unique())}\")\n",
    "\n",
    "    print(\"\\nðŸ“Š Material breakdown (bar plot grouping):\")\n",
    "    grouped_breakdown = source_data[\"material_category_grouped\"].value_counts()\n",
    "    for category, count in grouped_breakdown.items():\n",
    "        print(f\"   {category}: {count} papers\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"ðŸŽ‰ ALL VISUALIZATIONS COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Quick overall summary\n",
    "print(\"\\nðŸ“Š OVERALL DATA SUMMARY:\")\n",
    "print(\"=\" * 50)\n",
    "for source in sources:\n",
    "    source_count = len(df[df[\"source\"] == source])\n",
    "    print(f\"{source.upper()}: {source_count} papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds_paper = load_dataset(\n",
    "    \"LeMaterial/LeMat-Synth-Papers\", subset=\"full\", split=\"arxiv\"\n",
    ")\n",
    "\n",
    "df_paper = ds_paper.to_pandas()\n",
    "\n",
    "df_paper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_folder = (\n",
    "    \"/Users/magdalenalederbauer/Code/lematerial-llm-synthesis/annotations\"\n",
    ")\n",
    "\n",
    "# for every subdir in annotation_folder\n",
    "for subdir in os.listdir(annotation_folder):\n",
    "    # id = name of subdir\n",
    "    id = subdir\n",
    "    id = id.replace(\"cond-mat.\", \"cond-mat/\")\n",
    "    synthesis_procedures_of_paper = df_paper[df_paper[\"id\"] == id]\n",
    "    url_of_paper = (\n",
    "        synthesis_procedures_of_paper[\"pdf_url\"]\n",
    "        .values[0]\n",
    "        .replace(\"https://\", \"\")\n",
    "    )\n",
    "    matched_lemat_synth_entry = df[df[\"paper_url\"].str.contains(url_of_paper)]\n",
    "    if len(matched_lemat_synth_entry) == 0:\n",
    "        continue\n",
    "    if (\n",
    "        matched_lemat_synth_entry[\"synthesized_material\"].values[0]\n",
    "        == \"No materials synthesized\"\n",
    "    ):\n",
    "        continue\n",
    "\n",
    "    # result_llm = subdir/result.json\n",
    "    result_llm = os.path.join(annotation_folder, subdir, \"result.json\")\n",
    "    result_human = os.path.join(annotation_folder, subdir, \"result_human.json\")\n",
    "\n",
    "    # load llm_ontology as json\n",
    "    llm_ontology = json.loads(open(result_llm).read())\n",
    "    try:\n",
    "        human_ontology = json.loads(open(result_human).read())\n",
    "    except FileNotFoundError:\n",
    "        # print(f\"No human ontology for {id}\")\n",
    "        # human ontology is a list of empty dicts in same format as llm_ontology\n",
    "        human_ontology = [{} for _ in llm_ontology]\n",
    "\n",
    "    for idx, (item_llm, item_human) in enumerate(\n",
    "        zip(llm_ontology, human_ontology)\n",
    "    ):\n",
    "        mat_name = item_llm[\"material\"]\n",
    "        synthesis = item_llm[\"synthesis\"]\n",
    "        evaluation_llm = item_llm[\"evaluation\"]\n",
    "        evaluation_human = item_human[\"evaluation\"] if item_human else None\n",
    "        # fill the first row of matched_lemat_synth_entry with the values\n",
    "        try:\n",
    "            matched_lemat_synth_entry.iloc[idx] = {\n",
    "                \"synthesized_material\": mat_name,\n",
    "                \"synthesis\": synthesis,\n",
    "                \"synthesis_extraction_performance_llm\": evaluation_llm,\n",
    "                \"synthesis_extraction_performance_human\": evaluation_human,\n",
    "            }\n",
    "        except Exception:\n",
    "            print(f\"Error filling row {idx} of {id}\")\n",
    "            print(matched_lemat_synth_entry)\n",
    "            print(mat_name)\n",
    "            print(synthesis)\n",
    "            print(evaluation_llm)\n",
    "            print(evaluation_human)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_ontology[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_lemat_synth_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
