{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse ChemRxiv\n",
    "\n",
    "## Download papers from the ChemRxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import chemrxiv\n",
    "import pandas as pd\n",
    "\n",
    "client = chemrxiv.Client()\n",
    "search = chemrxiv.Search(\n",
    "    limit=29950,  # this is the total # papers of papers as of June 5 2025\n",
    "    # limit=2995,\n",
    "    sort=chemrxiv.SortCriterion.CITATION_COUNT_DESC,\n",
    ")\n",
    "# This takes ~1.5hrs to run!\n",
    "results = list(client.results(search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../../../data/\"\n",
    "\n",
    "\n",
    "def safe_convert_to_string(value):\n",
    "    \"\"\"Convert any value to a string, handling lists, dicts, etc.\"\"\"\n",
    "    if value is None:\n",
    "        return \"\"\n",
    "    elif isinstance(value, (list | tuple)):\n",
    "        return \"; \".join(str(item) for item in value)\n",
    "    elif isinstance(value, dict):\n",
    "        return str(\n",
    "            value\n",
    "        )  # or you could do json.dumps(value) for better formatting\n",
    "    else:\n",
    "        return str(value)\n",
    "\n",
    "\n",
    "def extract_authors(authors_list):\n",
    "    \"\"\"Extract author names from the authors list\"\"\"\n",
    "    if not authors_list:\n",
    "        return \"\"\n",
    "    author_names = []\n",
    "    for author in authors_list:\n",
    "        if isinstance(author, dict):\n",
    "            first_name = author.get(\"firstName\", \"\")\n",
    "            last_name = author.get(\"lastName\", \"\")\n",
    "            full_name = f\"{first_name} {last_name}\".strip()\n",
    "            if full_name:\n",
    "                author_names.append(full_name)\n",
    "    return \"; \".join(author_names)\n",
    "\n",
    "\n",
    "def extract_categories(categories_list):\n",
    "    \"\"\"Extract category names from the categories list\"\"\"\n",
    "    if not categories_list:\n",
    "        return \"\"\n",
    "    category_names = []\n",
    "    for category in categories_list:\n",
    "        if isinstance(category, dict) and \"name\" in category:\n",
    "            category_names.append(category[\"name\"])\n",
    "    return \"; \".join(category_names)\n",
    "\n",
    "\n",
    "def extract_metric_value(metrics_list, description):\n",
    "    \"\"\"Extract specific metric value by description\"\"\"\n",
    "    if not metrics_list:\n",
    "        return \"\"\n",
    "    for metric in metrics_list:\n",
    "        if (\n",
    "            isinstance(metric, dict)\n",
    "            and metric.get(\"description\") == description\n",
    "        ):\n",
    "            return str(metric.get(\"value\", \"\"))\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# Create empty DataFrame\n",
    "df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"id\",\n",
    "        \"title\",\n",
    "        \"authors\",\n",
    "        \"abstract\",\n",
    "        \"doi\",\n",
    "        \"published_date\",\n",
    "        \"updated_date\",\n",
    "        \"categories\",\n",
    "        \"license\",\n",
    "        \"pdf_url\",\n",
    "        \"views_count\",\n",
    "        \"read_count\",\n",
    "        \"citation_count\",\n",
    "        \"keywords\",\n",
    "        \"text_paper\",\n",
    "        \"text_si\",\n",
    "    ]\n",
    ")\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "for paper in results:\n",
    "    try:\n",
    "        # Use the raw data directly\n",
    "        paper_raw = paper._raw\n",
    "        # Extract values from raw data\n",
    "        id_val = safe_convert_to_string(paper_raw.get(\"id\", \"\"))\n",
    "        title = safe_convert_to_string(paper_raw.get(\"title\", \"\"))\n",
    "        authors = extract_authors(paper_raw.get(\"authors\", []))\n",
    "        abstract = safe_convert_to_string(paper_raw.get(\"abstract\", \"\"))\n",
    "        doi = safe_convert_to_string(paper_raw.get(\"doi\", \"\"))\n",
    "        published_date = safe_convert_to_string(\n",
    "            paper_raw.get(\"publishedDate\", \"\")\n",
    "        )\n",
    "        updated_date = safe_convert_to_string(\n",
    "            paper_raw.get(\"submittedDate\", \"\")\n",
    "        )\n",
    "        categories = extract_categories(paper_raw.get(\"categories\", []))\n",
    "        # Extract license name\n",
    "        license_info = paper_raw.get(\"license\", {})\n",
    "        license_val = (\n",
    "            license_info.get(\"name\", \"\")\n",
    "            if isinstance(license_info, dict)\n",
    "            else safe_convert_to_string(license_info)\n",
    "        )\n",
    "        # Extract PDF URL\n",
    "        asset_info = paper_raw.get(\"asset\", {})\n",
    "        pdf_url = \"\"\n",
    "        if isinstance(asset_info, dict) and \"original\" in asset_info:\n",
    "            pdf_url = asset_info[\"original\"].get(\"url\", \"\")\n",
    "        # Extract metrics\n",
    "        metrics = paper_raw.get(\"metrics\", [])\n",
    "        views_count = extract_metric_value(metrics, \"Abstract Views\")\n",
    "        citation_count = extract_metric_value(metrics, \"Citations\")\n",
    "        read_count = extract_metric_value(\n",
    "            metrics, \"Content Downloads\"\n",
    "        )  # Using downloads as read count\n",
    "        # Extract keywords\n",
    "        keywords = safe_convert_to_string(paper_raw.get(\"keywords\", []))\n",
    "        text_paper = \"\"\n",
    "        text_si = \"\"\n",
    "        # Create new row\n",
    "        new_row = {\n",
    "            \"id\": id_val,\n",
    "            \"title\": title,\n",
    "            \"authors\": authors,\n",
    "            \"abstract\": abstract,\n",
    "            \"doi\": doi,\n",
    "            \"published_date\": published_date,\n",
    "            \"updated_date\": updated_date,\n",
    "            \"categories\": categories,\n",
    "            \"license\": license_val,\n",
    "            \"pdf_url\": pdf_url,\n",
    "            \"views_count\": views_count,\n",
    "            \"read_count\": read_count,\n",
    "            \"citation_count\": citation_count,\n",
    "            \"keywords\": keywords,\n",
    "            \"text_paper\": text_paper,\n",
    "            \"text_si\": text_si,\n",
    "        }\n",
    "        # Add row to DataFrame\n",
    "        df.loc[len(df)] = new_row\n",
    "        print(f\"Added: {title[:50]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing paper: {e}\")\n",
    "        continue\n",
    "# Save to CSV\n",
    "df.to_csv(directory + \"arxiv_papers.csv\", index=False)\n",
    "print(f\"\\nSaved {len(df)} papers to {directory}arxiv_papers.csv\")\n",
    "# Display the DataFrame\n",
    "df\n",
    "\n",
    "# The dataset is loaded to huggingface via the CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after running this codeblock, run `huggingface-cli upload <name-of-dataset> ./data/arxiv_papers.csv --repo-type=dataset`. To update the repository, set the filter of the data to be after the parsing date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading raw dataset from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"magdaroni/chemrxiv-dev\", split=\"train\")\n",
    "\n",
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
